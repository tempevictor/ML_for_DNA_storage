{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Analysis </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference and blast analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count the number of single references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all ids and all sequences are unique\n",
    "# for 3XR6 dataset\n",
    "def check_ids_seqs(referenceFile):\n",
    "    # assert it is a fasta file\n",
    "    assert referenceFile[-5:] == \"fasta\"\n",
    "    # if full in the reference name, headers are present\n",
    "    cropped = True\n",
    "    if \"full\" in referenceFile:\n",
    "        cropped = False\n",
    "    #dictionaries to keep track of the count of unqiue id and sequence\n",
    "    unique_id = {}\n",
    "    unique_seq = {}\n",
    "    total_count = 0\n",
    "    with open(referenceFile, 'r') as f:\n",
    "        for index, line in enumerate(f):\n",
    "            if index%2==0:\n",
    "                assert line[0] == '>'\n",
    "                line = line.strip(\"\\n\").strip()\n",
    "                ref_id = int(line[9:]) #only the id not the \"bc\" part in 3XR6 dataset\n",
    "                if(ref_id not in unique_id):\n",
    "                    unique_id[ref_id] = 1\n",
    "                else:\n",
    "                    unique_id[ref_id] += 1\n",
    "            else:\n",
    "                assert line[0] in ['A', 'C', 'T', 'G']\n",
    "                seq = line.strip(\"\\n\").strip()\n",
    "                if not cropped:\n",
    "                    seq = seq[25:50]\n",
    "                if(seq not in unique_seq):\n",
    "                    unique_seq[seq] = 1\n",
    "                else:\n",
    "                    unique_seq[seq] += 1\n",
    "                total_count += 1\n",
    "    abnormality_detected = False\n",
    "    # check duplicates for ids\n",
    "    it = 1\n",
    "    missing_list = []\n",
    "    for key_id in unique_id:\n",
    "        if(unique_id[key_id]>1):\n",
    "            print(\"Id \" + key_id + \" has: \" + str(unique_id[key_id]) + \"occurences\")\n",
    "            abnormality_detected = True\n",
    "        if(key_id != it):\n",
    "            for i in range(it, key_id):\n",
    "                missing_list.append(i)\n",
    "            it = key_id + 1\n",
    "        else:\n",
    "            it +=1\n",
    "    print(\"Missing ids: \" + str(missing_list))\n",
    "    # check duplicates for sequences\n",
    "    for seq_key in unique_seq:\n",
    "        if(unique_seq[seq_key]>1):\n",
    "            print(\"Sequence \" + seq_key + \" has: \" + str(unique_seq[seq_key]) + \"occurences\")\n",
    "            abnormality_detected = True\n",
    "    # In the case nothing abnormal was found        \n",
    "    if not abnormality_detected:\n",
    "        print(\"All sequences and ids are unique\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing ids: [721, 812, 3698]\n",
      "All sequences and ids are unique\n"
     ]
    }
   ],
   "source": [
    "referenceFile = filedialog.askopenfilename()\n",
    "check_ids_seqs(referenceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of references in a blastn file\n",
    "def count_ids_f5(fast5Folder):\n",
    "    id_count = {}\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "\n",
    "        read_list = list(fast5_data.items())\n",
    "        for i in range(len(read_list)):\n",
    "            readstep = (read_list[i])\n",
    "            read = readstep[0]\n",
    "            raw_id = fast5_data[read+'/Raw'].attrs['read_id'].decode('UTF-8')\n",
    "            if raw_id not in id_count:\n",
    "                    id_count[raw_id] = 1\n",
    "            else:\n",
    "                id_count[raw_id] += 1\n",
    "    above2 = []\n",
    "    for key in id_count.keys():\n",
    "        num = id_count[key]\n",
    "        if num >= 2 :\n",
    "            above2.append(key)\n",
    "    print(\"Number of unique ids: \" + str(len(id_count.keys())))\n",
    "    print(\"Total number of ids: \" + str(sum(id_count.values())))\n",
    "    print(\"Difference: \" + str(sum(id_count.values()) - len(id_count.keys()) ) )\n",
    "    print(\"Above2: \" + str(len(above2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Number of unique ids: 158581\n",
      "Total number of ids: 158581\n",
      "Difference: 0\n",
      "Above2: 0\n",
      "\n",
      "*********** Flowcell 2 *********** \n"
     ]
    }
   ],
   "source": [
    "f5Base = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/fast5s_original/\"\n",
    "\n",
    "## 1a-42k\n",
    "print(\"\\n*********** Flowcell 1 *********** \")\n",
    "folder = f5Base + \"1a-42k\"\n",
    "count_ids_f5(folder)\n",
    "\n",
    "## 2b-42k\n",
    "print(\"\\n*********** Flowcell 2 *********** \")\n",
    "folder = f5Base + \"2b-42k\"\n",
    "count_ids_f5(folder)\n",
    "\n",
    "## 3d-42k\n",
    "print(\"\\n*********** Flowcell 3 *********** \")\n",
    "folder = f5Base + \"3d-42k\"\n",
    "count_ids_f5(folder)\n",
    "\n",
    "## all\n",
    "print(\"\\n*********** All *********** \")\n",
    "folder = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/fast5s_original_all/\"\n",
    "count_ids_f5(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of references in a blastn file\n",
    "def count_ids_blast(blastnFile):\n",
    "    blast_ids = {}\n",
    "    with open(blastnFile, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == \">\":\n",
    "                content = line.strip(\"\\n\").strip().strip(\">\")\n",
    "                read_id = content.split()[0]\n",
    "                if read_id not in blast_ids:\n",
    "                    blast_ids[read_id] = 1\n",
    "                else:\n",
    "                    blast_ids[read_id] += 1\n",
    "    above2 = []\n",
    "    for key in blast_ids.keys():\n",
    "        num = blast_ids[key]\n",
    "        if num >= 2 :\n",
    "            above2.append(key)\n",
    "    print(\"Number of unique ids: \" + str(len(blast_ids.keys())))\n",
    "    print(\"Total number of ids: \" + str(sum(blast_ids.values())))\n",
    "    print(\"Difference: \" + str(sum(blast_ids.values()) - len(blast_ids.keys()) ) )\n",
    "    print(\"Above2: \" + str(len(above2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate files\n",
    "blastnBase = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "with open(blastnBase + \"fc123s_42k.out\", 'w') as outfile:\n",
    "    for fname in [\"fc1s_42k.out\", \"fc2s_42k.out\", \"fc3s_42k.out\"]:\n",
    "        with open(blastnBase + fname, 'r') as readfile:\n",
    "            for line in readfile:\n",
    "                outfile.write(line)\n",
    "\n",
    "\n",
    "with open(blastnBase + \"fc123s_42k_addonly.out\", 'w') as outfile:\n",
    "    for fname in [\"fc1s_42k_addonly.out\", \"fc2s_42k_addonly.out\", \"fc3s_42k_addonly.out\"]:\n",
    "        with open(blastnBase + fname, 'r') as readfile:\n",
    "            for line in readfile:\n",
    "                outfile.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Number of unique ids: 40201\n",
      "Total number of ids: 41465\n",
      "Difference: 1264\n",
      "Above2: 1226\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Number of unique ids: 14599\n",
      "Total number of ids: 14800\n",
      "Difference: 201\n",
      "Above2: 194\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Number of unique ids: 12038\n",
      "Total number of ids: 12223\n",
      "Difference: 185\n",
      "Above2: 181\n",
      "\n",
      "*********** All *********** \n",
      "Number of unique ids: 66838\n",
      "Total number of ids: 68488\n",
      "Difference: 1650\n",
      "Above2: 1601\n"
     ]
    },
    {
     "data": {
      "text/plain": "' NB: ADD HISTOGTRAM ?? '"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blastnBase = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "\n",
    "## 1a-42k\n",
    "print(\"\\n*********** Flowcell 1 *********** \")\n",
    "blastnFile = blastnBase + \"fc1s_42k.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## 2b-42k\n",
    "print(\"\\n*********** Flowcell 2 *********** \")\n",
    "blastnFile = blastnBase + \"fc2s_42k.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## 3d-42k\n",
    "print(\"\\n*********** Flowcell 3 *********** \")\n",
    "blastnFile = blastnBase + \"fc3s_42k.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## all\n",
    "print(\"\\n*********** All *********** \")\n",
    "blastnFile = blastnBase + \"fc123s_42k.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "''' NB: ADD HISTOGTRAM ?? '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********** Flowcell 1 _addonly *********** \n",
      "Number of unique ids: 61517\n",
      "Total number of ids: 63964\n",
      "Difference: 2447\n",
      "Above2: 2378\n",
      "\n",
      "*********** Flowcell 2 _addonly*********** \n",
      "Number of unique ids: 26071\n",
      "Total number of ids: 26590\n",
      "Difference: 519\n",
      "Above2: 512\n",
      "\n",
      "*********** Flowcell 3 _addonly*********** \n",
      "Number of unique ids: 21511\n",
      "Total number of ids: 21991\n",
      "Difference: 480\n",
      "Above2: 472\n",
      "\n",
      "*********** All _addonly*********** \n",
      "Number of unique ids: 109099\n",
      "Total number of ids: 112545\n",
      "Difference: 3446\n",
      "Above2: 3362\n"
     ]
    },
    {
     "data": {
      "text/plain": "' NB: ADD HISTOGTRAM ?? '"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blastnBase = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "\n",
    "## 1a-42k\n",
    "print(\"\\n*********** Flowcell 1 _addonly *********** \")\n",
    "blastnFile = blastnBase + \"fc1s_42k_addonly.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## 2b-42k\n",
    "print(\"\\n*********** Flowcell 2 _addonly*********** \")\n",
    "blastnFile = blastnBase + \"fc2s_42k_addonly.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## 3d-42k\n",
    "print(\"\\n*********** Flowcell 3 _addonly*********** \")\n",
    "blastnFile = blastnBase + \"fc3s_42k_addonly.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "## all\n",
    "print(\"\\n*********** All _addonly*********** \")\n",
    "blastnFile = blastnBase + \"fc123s_42k_addonly.out\"\n",
    "count_ids_blast(blastnFile)\n",
    "\n",
    "''' NB: ADD HISTOGTRAM ?? '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of reads that align to several references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Number of reads that align to several references'''\n",
    "def count_reads_with_severalRef(blastnFileList):\n",
    "    id_dic = {}\n",
    "    for blastnFile in blastnFileList:\n",
    "        with open(blastnFile, 'r') as f:\n",
    "            current_querry = ''\n",
    "            for line in f:\n",
    "                if line[0:6] == \"Query=\":\n",
    "                    current_querry = line.split()[1]\n",
    "                elif line[0] == '>':\n",
    "                    read_id = line[1:].split()[0]\n",
    "                    if read_id not in id_dic:\n",
    "                        id_dic[read_id] = set([current_querry])\n",
    "                    else:\n",
    "                        id_dic[read_id].add(current_querry)\n",
    "    count_severalRef = 0\n",
    "    several_dic = set()\n",
    "    for key in id_dic:\n",
    "        if len(id_dic[key]) > 1:\n",
    "            count_severalRef += 1\n",
    "            several_dic.add(key)\n",
    "    print(\"Number of read_ids that align to several references: \" + str(count_severalRef))\n",
    "    return(several_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of read_ids that align to several references: 1601\n"
     ]
    }
   ],
   "source": [
    "blastn_path = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "blastnFileList = [blastn_path + \"fc1s_42k.out\",\n",
    "                  blastn_path + \"fc2s_42k.out\",\n",
    "                   blastn_path + \"fc3s_42k.out\"]\n",
    "                   \n",
    "several_dic = count_reads_with_severalRef(blastnFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each reference, how many reads align to it accross all flowcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Number of reads per rereference\n",
    "def read_id_per_reference(blastnFileList):\n",
    "    nb_read_id = 0\n",
    "    ref_dic = {}\n",
    "    for blastnFile in blastnFileList:\n",
    "        with open(blastnFile, 'r') as f:\n",
    "            current_querry = ''\n",
    "            for line in f:\n",
    "                if line[0:6] == \"Query=\":\n",
    "                    current_querry = line.split()[1]\n",
    "                    if current_querry not in ref_dic:\n",
    "                        nb_read_id += 1\n",
    "                        ref_dic[current_querry] = set()\n",
    "                elif line[0] == '>':\n",
    "                    read_id = line[1:].split()[0]\n",
    "                    ref_dic[current_querry].add(read_id)\n",
    "\n",
    "    nb_ref_sev_align = 0      \n",
    "    max_num_reads = 0\n",
    "    max_key = ''\n",
    "    for key in ref_dic:\n",
    "        if len(ref_dic[key]) > 1:\n",
    "            nb_ref_sev_align += 1\n",
    "        if len(ref_dic[key]) > max_num_reads:\n",
    "            max_num_reads = len(ref_dic[key])\n",
    "            max_key = key\n",
    "    print(\"Number of reference with more than one read id that align to it: \" + str(nb_ref_sev_align))\n",
    "    print(\"Total unique ref id: \" + str(nb_read_id))\n",
    "    print(\"Max number of reads \" + str(max_num_reads) + \" for the reference \" + str(max_key))\n",
    "    return(ref_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reference with more than one read id that align to it: 19418\n",
      "Total unique ref id: 42000\n",
      "Max number of reads 13 for the reference bc25mer_943\n"
     ]
    }
   ],
   "source": [
    "blastn_path = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "blastnFileList = [blastn_path + \"fc1s_42k.out\",\n",
    "                  blastn_path + \"fc2s_42k.out\",\n",
    "                   blastn_path + \"fc3s_42k.out\"]\n",
    "                   \n",
    "ref_dic = read_id_per_reference(blastnFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtered dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checks that read_ids in blastn are in fast5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of ids from blast file that are not present in the fast5 file\n",
    "def count_missing_id_fast5(blastnFile, fast5Folder):\n",
    "    # create dic of ids from fast5 file\n",
    "    raw_ids = {}\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        \n",
    "        read_list = list(fast5_data.items())\n",
    "        for i in range(len(read_list)):\n",
    "            readstep = (read_list[i])\n",
    "            read = readstep[0]\n",
    "            raw_id = fast5_data[read+'/Raw'].attrs['read_id'].decode('UTF-8')\n",
    "            \n",
    "            if raw_id not in raw_ids:\n",
    "                raw_ids[raw_id] = 1\n",
    "            else:\n",
    "                raw_ids[raw_id] += 1\n",
    "        fast5_data.close()\n",
    "    # create dic of ids from blastn file\n",
    "    blast_ids = {}\n",
    "    with open(blastnFile, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == \">\":\n",
    "                content = line.strip(\"\\n\").strip().strip(\">\")\n",
    "                read_id = content.split()[0]\n",
    "                if read_id not in blast_ids:\n",
    "                    blast_ids[read_id] = 1\n",
    "                else:\n",
    "                    blast_ids[read_id] += 1\n",
    "                   \n",
    "    # comput the number of missing elements\n",
    "    count_differences = 0\n",
    "    missing_ids = []\n",
    "    for key in blast_ids:\n",
    "        if key not in raw_ids:\n",
    "            count_differences+=1\n",
    "            missing_ids.append(key)\n",
    "    print(\"There are: \" + str(count_differences) + \" missing ids\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********** Flowcell 1 *********** \n",
      "There are: 0 missing ids\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "There are: 0 missing ids\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "There are: 0 missing ids\n"
     ]
    }
   ],
   "source": [
    "fast5_base = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "blastn_base = \"/media/victor/USB/MSc_basecall/Data/3XR6/ref_3xr6/blastn/\"\n",
    "\n",
    "\n",
    "## 1a-42k\n",
    "print(\"\\n*********** Flowcell 1 *********** \")\n",
    "fast5Folder = fast5_base + \"/1a-42k/\"\n",
    "blastnFile = blastn_base + \"fc1s_42k.out\"\n",
    "count_missing_id_fast5(blastnFile, fast5Folder)\n",
    "\n",
    "## 2b-42k\n",
    "print(\"\\n*********** Flowcell 2 *********** \")\n",
    "fast5Folder = fast5_base + \"/2b-42k/\"\n",
    "blastnFile = blastn_base + \"fc2s_42k.out\"\n",
    "count_missing_id_fast5(blastnFile, fast5Folder)\n",
    "\n",
    "## 3d-42k\n",
    "print(\"\\n*********** Flowcell 3 *********** \")\n",
    "fast5Folder = fast5_base + \"/3c-42k/\"\n",
    "blastnFile = blastn_base + \"fc3s_42k.out\"\n",
    "count_missing_id_fast5(blastnFile, fast5Folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of read in the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of the file without path and without extension\n",
    "def get_just_file_name(file_path):\n",
    "    file_path = file_path.strip()\n",
    "    splited_fname = file_path.split('/')\n",
    "    simple_file_name = splited_fname[-1]\n",
    "    simple_file_name = os.path.splitext(simple_file_name)[0]\n",
    "    return(simple_file_name)\n",
    "\n",
    "\n",
    "\n",
    "# count the number of reads fast5 files\n",
    "def count_read_ids_fast5(fast5Folder):\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    count_id = {}\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        short_file_name = get_just_file_name(fast5File)\n",
    "        read_list = list(fast5_data.items())\n",
    "        count_id[short_file_name] = len(read_list)\n",
    "        fast5_data.close()\n",
    "    return(count_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING WITH ENTIRE 120-LONG SEQUENCES\n",
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Initial number of reads: 158581\n",
      "After filtering, number of reads: 40201\n",
      "i.e. 25.35%\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Initial number of reads: 94307\n",
      "After filtering, number of reads: 14599\n",
      "i.e. 15.479999999999999%\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Initial number of reads: 89766\n",
      "After filtering, number of reads: 12038\n",
      "i.e. 13.41%\n"
     ]
    }
   ],
   "source": [
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "fast5base_filtered = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s_filtered_long/\"\n",
    "\n",
    "# Filtering using blastn e-value for the entire sequence\n",
    "print(\"FILTERING WITH ENTIRE 120-LONG SEQUENCES\") \n",
    "\n",
    "folders = [\"1a-42k/\", \"2b-42k/\", \"3d-42k/\"]\n",
    "for i in range(3):\n",
    "    print(\"\\n*********** Flowcell \" + str(i+1) + \" *********** \")\n",
    "    folder = folders[i]\n",
    "    fast5Folder_original = fast5base_original + folder\n",
    "    fast5Folder_filtered = fast5base_filtered + folder\n",
    "    dic_count_original = count_read_ids_fast5(fast5Folder_original)\n",
    "    dic_count_filtered = count_read_ids_fast5(fast5Folder_filtered)\n",
    "    sum_original = sum(dic_count_original.values())\n",
    "    sum_filtered = sum(dic_count_filtered.values())\n",
    "    print(\"Initial number of reads: \" + str(sum_original))\n",
    "    print(\"After filtering, number of reads: \" + str(sum_filtered))\n",
    "    print(\"i.e. \" + str(100 * round(sum_filtered/sum_original,4)) + \"%\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING WITH 25-LONG SEQUENCES OF INTEREST\n",
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Initial number of reads: 158581\n",
      "After filtering, number of reads: 61517\n",
      "i.e. 38.79%\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Initial number of reads: 94307\n",
      "After filtering, number of reads: 26071\n",
      "i.e. 27.639999999999997%\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Initial number of reads: 89766\n",
      "After filtering, number of reads: 21511\n",
      "i.e. 23.96%\n"
     ]
    }
   ],
   "source": [
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "fast5base_filtered = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s_filtered_short/\"\n",
    "\n",
    "# Filtering using blastn e-value for the entire sequence\n",
    "print(\"FILTERING WITH 25-LONG SEQUENCES OF INTEREST\") \n",
    "\n",
    "folders = [\"1a-42k/\", \"2b-42k/\", \"3d-42k/\"]\n",
    "for i in range(3):\n",
    "    print(\"\\n*********** Flowcell \" + str(i+1) + \" *********** \")\n",
    "    folder = folders[i]\n",
    "    fast5Folder_original = fast5base_original + folder\n",
    "    fast5Folder_filtered = fast5base_filtered + folder\n",
    "    dic_count_original = count_read_ids_fast5(fast5Folder_original)\n",
    "    dic_count_filtered = count_read_ids_fast5(fast5Folder_filtered)\n",
    "    sum_original = sum(dic_count_original.values())\n",
    "    sum_filtered = sum(dic_count_filtered.values())\n",
    "    print(\"Initial number of reads: \" + str(sum_original))\n",
    "    print(\"After filtering, number of reads: \" + str(sum_filtered))\n",
    "    print(\"i.e. \" + str(100 * round(sum_filtered/sum_original,4)) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count how many reads per fast5 file on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many reads in a fast5 file on average\n",
    "\n",
    "def count_average_reads_fast5(fast5Folder):\n",
    "    global_sum = 0\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    first_time = True\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        read_list = list(fast5_data.items())\n",
    "        length = len(read_list)\n",
    "        if first_time:\n",
    "            print(length)\n",
    "            first_time = False\n",
    "        global_sum += length\n",
    "        fast5_data.close()\n",
    "    average = global_sum / len(filenames)\n",
    "    print(\"There are \" + str(average) + \" reads per fast5 file on average\")\n",
    "    return(average)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING WITH 25-LONG SEQUENCES OF INTEREST\n",
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Original\n",
      "4000\n",
      "There are 3964.525 reads per fast5 file on average\n",
      "Filtered\n",
      "1561\n",
      "There are 1537.925 reads per fast5 file on average\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Original\n",
      "4000\n",
      "There are 3929.4583333333335 reads per fast5 file on average\n",
      "Filtered\n",
      "1455\n",
      "There are 1086.2916666666667 reads per fast5 file on average\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Original\n",
      "4000\n",
      "There are 3902.8695652173915 reads per fast5 file on average\n",
      "Filtered\n",
      "60\n",
      "There are 935.2608695652174 reads per fast5 file on average\n"
     ]
    }
   ],
   "source": [
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "fast5base_filtered = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s_filtered_short/\"\n",
    "\n",
    "# Filtering using blastn e-value for the entire sequence\n",
    "print(\"FILTERING WITH 25-LONG SEQUENCES OF INTEREST\") \n",
    "\n",
    "folders = [\"1a-42k/\", \"2b-42k/\", \"3d-42k/\"]\n",
    "for i in range(3):\n",
    "    print(\"\\n*********** Flowcell \" + str(i+1) + \" *********** \")\n",
    "    folder = folders[i]\n",
    "    fast5Folder_original = fast5base_original + folder\n",
    "    fast5Folder_filtered = fast5base_filtered + folder\n",
    "    print(\"Original\")\n",
    "    mean_length_original = count_average_reads_fast5(fast5Folder_original)\n",
    "    print(\"Filtered\")\n",
    "    mean_length_filtered = count_average_reads_fast5(fast5Folder_filtered)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### average signal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average signal lenght of a \n",
    "\n",
    "def count_average_reads_fast5(fast5Folder):\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    len_track = []\n",
    "    first = True\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        read_list = list(fast5_data.items())\n",
    "        for i in range(len(read_list)):\n",
    "            readstep = (read_list[i])\n",
    "            read = readstep[0]\n",
    "            signal_path = read + '/Raw/Signal'\n",
    "            sig = np.array(fast5_data.get(signal_path), dtype=np.float32)\n",
    "            sig_len = len(sig)\n",
    "            len_track.append(sig_len)\n",
    "        if first:\n",
    "            print(\"sum lengths first file: \" + str( sum(len_track)) )\n",
    "            first = False\n",
    "\n",
    "        fast5_data.close()\n",
    "    mean_len = np.mean(np.array(len_track))\n",
    "    print(\"There are \" + str(mean_len) + \" points per signal on average\")\n",
    "    return(mean_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING WITH 25-LONG SEQUENCES OF INTEREST\n",
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Original\n",
      "sum lengths first file: 19789662\n",
      "There are 5183.972184561832 points per signal on average\n",
      "Filtered\n",
      "sum lengths first file: 6961590\n",
      "There are 4532.765073069233 points per signal on average\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Original\n",
      "sum lengths first file: 20731984\n",
      "There are 5367.725545293562 points per signal on average\n",
      "Filtered\n",
      "sum lengths first file: 7616893\n",
      "There are 4820.364466265199 points per signal on average\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Original\n",
      "sum lengths first file: 20146232\n",
      "There are 5600.4700220573495 points per signal on average\n",
      "Filtered\n",
      "sum lengths first file: 445792\n",
      "There are 4861.318023336898 points per signal on average\n"
     ]
    }
   ],
   "source": [
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "fast5base_filtered = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s_filtered_short/\"\n",
    "\n",
    "# Filtering using blastn e-value for the entire sequence\n",
    "print(\"FILTERING WITH 25-LONG SEQUENCES OF INTEREST\") \n",
    "\n",
    "folders = [\"1a-42k/\", \"2b-42k/\", \"3d-42k/\"]\n",
    "for i in range(3):\n",
    "    print(\"\\n*********** Flowcell \" + str(i+1) + \" *********** \")\n",
    "    folder = folders[i]\n",
    "    fast5Folder_original = fast5base_original + folder\n",
    "    fast5Folder_filtered = fast5base_filtered + folder\n",
    "    print(\"Original\")\n",
    "    mean_length_original = count_average_reads_fast5(fast5Folder_original)\n",
    "    print(\"Filtered\")\n",
    "    mean_length_filtered = count_average_reads_fast5(fast5Folder_filtered)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average signal lenght of a \n",
    "\n",
    "def count_average_reads_fast5_bis(fast5Folder):\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    len_track = []\n",
    "    first = True\n",
    "    print(len(filenames))\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        raw_attr = fast5_data['Raw/Reads/']\n",
    "        read_name = list(raw_attr.keys())[0]\n",
    "        raw_signal = raw_attr[read_name + '/Signal'][()]\n",
    "        sig = np.array(raw_signal, dtype=np.float32)\n",
    "        sig_len = len(sig)\n",
    "        len_track.append(sig_len)\n",
    "        if first:\n",
    "            print(\"sum lengths first file: \" + str( sum(len_track)) )\n",
    "            first = False\n",
    "\n",
    "        fast5_data.close()\n",
    "    mean_len = np.mean(np.array(len_track))\n",
    "    print(\"There are \" + str(mean_len) + \" points per signal on average\")\n",
    "    return(mean_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** natural DNA data ******\n",
      "808\n",
      "sum lengths first file: 112357\n",
      "There are 150612.94925742573 points per signal on average\n"
     ]
    }
   ],
   "source": [
    "print(\"****** natural DNA data ******\" )\n",
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/Klebsiella_pneumoniae_KSB1_7F/training_fast5s/0000/\"\n",
    "\n",
    "mean_length_original = count_average_reads_fast5_bis(fast5base_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count how many signals inferior to 2048 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of signals with less than 2048 points\n",
    "\n",
    "def count2048reads(fast5Folder):\n",
    "    filenames = glob.glob(fast5Folder + \"/*.fast5\")\n",
    "    inf2048 = 0\n",
    "    total = 0\n",
    "    for fast5File in filenames:\n",
    "        # try to open fast5 file\n",
    "        if not fast5File.endswith('fast5'):\n",
    "            print(\"Not a fast5 file\")\n",
    "            return\n",
    "        try:\n",
    "            fast5_data = h5py.File(fast5File, 'r')\n",
    "        except IOError:\n",
    "            print('Error opening file')\n",
    "            return\n",
    "        read_list = list(fast5_data.items())\n",
    "        for i in range(len(read_list)):\n",
    "            readstep = (read_list[i])\n",
    "            read = readstep[0]\n",
    "            signal_path = read + '/Raw/Signal'\n",
    "            sig = np.array(fast5_data.get(signal_path), dtype=np.float32)\n",
    "            sig_len = len(sig)\n",
    "            if(sig_len<= 2048):\n",
    "                inf2048 += 1\n",
    "            total += 1\n",
    "        fast5_data.close()\n",
    "    print(\"There are \" + str(inf2048) + \" reads that have less than 2048 files\")\n",
    "    print(\"There are \" + str(total) + \" reads in total\")\n",
    "    print(\"ie \" + str(round(inf2048 / total, 4)*100) + \"%\")\n",
    "    return(inf2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILTERING WITH 25-LONG SEQUENCES OF INTEREST\n",
      "\n",
      "*********** Flowcell 1 *********** \n",
      "Original\n",
      "There are 2 reads that have less than 2048 files\n",
      "There are 158581 reads in total\n",
      "ie 0.0%\n",
      "Filtered\n",
      "There are 2 reads that have less than 2048 files\n",
      "There are 61517 reads in total\n",
      "ie 0.0%\n",
      "\n",
      "*********** Flowcell 2 *********** \n",
      "Original\n",
      "There are 0 reads that have less than 2048 files\n",
      "There are 94307 reads in total\n",
      "ie 0.0%\n",
      "Filtered\n",
      "There are 0 reads that have less than 2048 files\n",
      "There are 26071 reads in total\n",
      "ie 0.0%\n",
      "\n",
      "*********** Flowcell 3 *********** \n",
      "Original\n",
      "There are 0 reads that have less than 2048 files\n",
      "There are 89766 reads in total\n",
      "ie 0.0%\n",
      "Filtered\n",
      "There are 0 reads that have less than 2048 files\n",
      "There are 21511 reads in total\n",
      "ie 0.0%\n"
     ]
    }
   ],
   "source": [
    "fast5base_original = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s/\"\n",
    "fast5base_filtered = \"/media/victor/USB/MSc_basecall/Data/3XR6/fast5s_filtered_short/\"\n",
    "\n",
    "# Filtering using blastn e-value for the entire sequence\n",
    "print(\"FILTERING WITH 25-LONG SEQUENCES OF INTEREST\") \n",
    "\n",
    "folders = [\"1a-42k/\", \"2b-42k/\", \"3d-42k/\"]\n",
    "for i in range(3):\n",
    "    print(\"\\n*********** Flowcell \" + str(i+1) + \" *********** \")\n",
    "    folder = folders[i]\n",
    "    fast5Folder_original = fast5base_original + folder\n",
    "    fast5Folder_filtered = fast5base_filtered + folder\n",
    "    print(\"Original\")\n",
    "    mean_length_original = count2048reads(fast5Folder_original)\n",
    "    print(\"Filtered\")\n",
    "    mean_length_filtered = count2048reads(fast5Folder_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "name": "python377jvsc74a57bd01542ee2726d20ca6ce38c73be6f1d0781bc1da10a4a2880694256f254b885628"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}